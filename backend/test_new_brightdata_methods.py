#!/usr/bin/env python3
"""
Test the newly added BrightData methods
"""
import os
import django
from dotenv import load_dotenv

# Load environment
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
django.setup()

from brightdata_integration.services import BrightDataAutomatedBatchScraper
from brightdata_integration.models import BrightDataConfig, BrightDataScraperRequest, BrightDataBatchJob
from users.models import Project

def test_new_methods():
    print("=== TESTING NEW BRIGHTDATA METHODS ===")
    print()
    
    # Get or create a test project
    project, created = Project.objects.get_or_create(
        name="Test Project", 
        defaults={'description': 'Test project for BrightData'}
    )
    
    # Create a test batch job
    scraper = BrightDataAutomatedBatchScraper()
    
    batch_job = BrightDataBatchJob.objects.create(
        name="Test Batch Job",
        project=project,
        platforms_to_scrape=['instagram'],
        num_of_posts=10
    )
    print(f"‚úÖ Created test batch job: {batch_job.id}")
    
    # Get Instagram config
    config = BrightDataConfig.objects.filter(platform='instagram', is_active=True).first()
    if not config:
        print("‚ùå No Instagram config found")
        return False
    
    print(f"‚úÖ Using config: {config.name}")
    print(f"   API Token: {config.api_token[:20]}...")
    print(f"   Dataset ID: {config.dataset_id}")
    print()
    
    # Create a test scraper request
    scraper_request = BrightDataScraperRequest.objects.create(
        config=config,
        batch_job=batch_job,
        platform='instagram',
        content_type='posts',
        target_url='https://www.instagram.com/nike/',
        source_name='Test Instagram Scraper',
        status='pending'
    )
    print(f"‚úÖ Created scraper request: {scraper_request.id}")
    print()
    
    # Test the _prepare_request_payload method
    print("üß™ Testing _prepare_request_payload...")
    payload = scraper._prepare_request_payload('instagram', batch_job, scraper_request)
    print(f"   Payload: {payload}")
    print()
    
    # Test the _execute_brightdata_request method
    print("üöÄ Testing _execute_brightdata_request...")
    print("   This will make an ACTUAL request to BrightData!")
    print(f"   Target URL: https://brightdata.com/api/datasets/{config.dataset_id}/trigger")
    print(f"   Using API token: {config.api_token[:20]}...")
    print()
    
    success = scraper._execute_brightdata_request(scraper_request, payload)
    
    # Refresh the scraper request to see updated status
    scraper_request.refresh_from_db()
    
    print(f"‚úÖ Request execution result: {success}")
    print(f"üìä Scraper request status: {scraper_request.status}")
    
    if scraper_request.error_message:
        print(f"‚ùå Error message: {scraper_request.error_message}")
    
    if scraper_request.response_data:
        print(f"‚úÖ Response data: {scraper_request.response_data}")
    
    print()
    if success:
        print("üéâ SUCCESS! BrightData received the request!")
        print("   Check your BrightData dashboard for the new job.")
    else:
        print("‚ùå Request failed, but the methods are working.")
        print("   This might be due to:")
        print("   - Incorrect dataset ID")
        print("   - API endpoint URL")
        print("   - Account permissions")
    
    return success

if __name__ == "__main__":
    print("üéØ TESTING THE NEWLY ADDED BRIGHTDATA METHODS")
    print("=" * 60)
    print()
    
    success = test_new_methods()
    
    print()
    print("=" * 60)
    if success:
        print("üéâ METHODS WORKING! BrightData integration is now complete!")
    else:
        print("‚ö†Ô∏è  Methods added but API calls need refinement.")
        print("   The core issue (missing methods) is now fixed!")