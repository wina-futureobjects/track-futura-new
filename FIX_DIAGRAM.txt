================================================================================
                    BRIGHTDATA STORAGE FIX - VISUAL DIAGRAM
================================================================================

BEFORE FIX (BROKEN) âŒ
--------------------------------------------------------------------------------

User Action: Start Scrape on Workflow Page
    â†“
Backend: workflow/views.py start() endpoint
    â”œâ”€ âœ… Create batch_job
    â”œâ”€ âŒ NO UnifiedRunFolder created
    â”œâ”€ âŒ NO BrightDataScraperRequest with folder_id
    â””â”€ âœ… Trigger BrightData API
    â†“
BrightData: Scrapes Instagram/Facebook/etc (2-5 minutes)
    â†“
BrightData: Sends webhook with scraped data
    â†“
Backend: webhook receives data
    â”œâ”€ Finds scraper_request? âŒ NO (doesn't exist or has no folder_id)
    â”œâ”€ Try to create BrightDataScrapedPost with folder_id? âŒ NO folder_id!
    â””â”€ Data is LOST or ORPHANED
    â†“
User: Navigates to /data-storage/run/293
    â”œâ”€ Frontend: Route doesn't match âŒ
    â””â”€ Error: "No folder identifier provided"
    â†“
Result: NO DATA VISIBLE âŒ


AFTER FIX (WORKING) âœ…
--------------------------------------------------------------------------------

User Action: Start Scrape on Workflow Page
    â†“
Backend: workflow/views.py start() endpoint
    â”œâ”€ âœ… Create batch_job
    â”œâ”€ âœ… Create UnifiedRunFolder (e.g., ID 293)
    â”‚      name: "Instagram Data - Project Name"
    â”‚      folder_type: "job"
    â”‚      platform_code: "instagram"
    â”‚
    â”œâ”€ âœ… Create BrightDataScraperRequest for each URL
    â”‚      platform: "instagram"
    â”‚      folder_id: 293  â† CRITICAL LINK!
    â”‚      batch_job: batch_job
    â”‚      status: "processing"
    â”‚
    â””â”€ âœ… Trigger BrightData API
        â””â”€ Returns snapshot_id
            â””â”€ âœ… Update scraper_request.snapshot_id
    â†“
BrightData: Scrapes Instagram/Facebook/etc (2-5 minutes)
    â†“
BrightData: Sends webhook with scraped data
    {
        "snapshot_id": "s_abc123",
        "posts": [ {...}, {...}, {...} ]
    }
    â†“
Backend: webhook receives data (brightdata_integration/views.py:1541)
    â”œâ”€ âœ… Find scraper_request by snapshot_id
    â”œâ”€ âœ… Get folder_id from scraper_request (folder_id=293)
    â”œâ”€ âœ… Call _process_brightdata_results(data, platform, scraper_request)
    â”‚   â””â”€ Calls _create_brightdata_scraped_post() for each post
    â”‚       â””â”€ Creates BrightDataScrapedPost with folder_id=293
    â”œâ”€ âœ… Updates scraper_request.status = "completed"
    â””â”€ âœ… All posts saved to database linked to folder 293
    â†“
User: Navigates to /data-storage
    â””â”€ Sees folder "Instagram Data - Project Name" (ID 293)
        â””â”€ Click â†’ /data-storage/run/293
    â†“
Frontend: Route matches! (App.tsx line 282)
    <Route path=".../data-storage/run/:runId" />
    â””â”€ Loads JobFolderView with runId=293
    â†“
JobFolderView: Fetches data (JobFolderView.tsx line 281)
    â””â”€ GET /api/brightdata/data-storage/run/293/
    â†“
Backend API: data_storage_run_endpoint() (brightdata_integration/views.py:83)
    â”œâ”€ âœ… Finds scraper_request by run_id=293
    â”œâ”€ âœ… Gets folder_id from scraper_request
    â”œâ”€ âœ… Queries BrightDataScrapedPost.objects.filter(folder_id=293)
    â””â”€ âœ… Returns posts data
    â†“
Frontend: JobFolderView displays data
    â”œâ”€ âœ… Shows folder name
    â”œâ”€ âœ… Shows post count
    â”œâ”€ âœ… Shows all posts with:
    â”‚      - Content
    â”‚      - User
    â”‚      - Likes
    â”‚      - Comments
    â”‚      - Date
    â””â”€ âœ… Export CSV/JSON available
    â†“
Result: DATA VISIBLE! âœ…


KEY CHANGES MADE
--------------------------------------------------------------------------------

Backend (workflow/views.py):
    Line 277-284:  âœ… Create UnifiedRunFolder BEFORE scraping
    Line 295-304:  âœ… Create BrightDataScraperRequest with folder_id
    Line 318-322:  âœ… Update snapshot_id after trigger
    Line 336-339:  âœ… Cleanup on error

Frontend (App.tsx):
    Line 282-288:  âœ… Add /data-storage/run/:runId route


DATA LINK CHAIN (THE MAGIC)
--------------------------------------------------------------------------------

UnifiedRunFolder (folder_id=293)
    â†“ linked by folder_id
BrightDataScraperRequest (folder_id=293, snapshot_id="s_abc123")
    â†“ linked by snapshot_id
BrightData Webhook (snapshot_id="s_abc123")
    â†“ creates posts with folder_id
BrightDataScrapedPost (folder_id=293, content="...", likes=100, ...)
    â†“ queried by folder_id
Frontend Display (/data-storage/run/293)
    â†“
USER SEES DATA! ğŸ‰


ERROR HANDLING
--------------------------------------------------------------------------------

If BrightData API fails:
    âœ… Backend deletes UnifiedRunFolder
    âœ… Backend deletes BrightDataScraperRequest records
    âœ… No orphaned data
    âœ… Clean error message to user

If webhook fails:
    âœ… Folder stays in "processing" state
    âœ… User can retry
    âœ… No data loss


DEPLOYMENT
--------------------------------------------------------------------------------

Windows:    DEPLOY_COMPLETE_FIX.bat
Linux/Mac:  bash DEPLOY_STORAGE_FIX.sh

Or manually:
    git add backend/workflow/views.py frontend/src/App.tsx
    git commit -m "FIX: Complete BrightData data storage integration"
    git push upsun main


TESTING
--------------------------------------------------------------------------------

1. Workflow Management â†’ Start Scrape
2. Wait 2-5 minutes
3. Data Storage â†’ See folder with posts
4. Success! âœ…

Direct URL test:
    /organizations/1/projects/1/data-storage/run/293

Expected:
    âœ… Posts displayed
    âœ… Can export CSV/JSON
    âœ… No errors


================================================================================
                                END OF DIAGRAM
================================================================================
