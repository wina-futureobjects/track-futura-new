#!/usr/bin/env python3

import requests
import json
from datetime import datetime, timedelta

def test_correct_scraping_run_format():
    print('üö® TESTING CORRECT SCRAPING-RUN FORMAT')
    print('=' * 50)

    base_url = 'https://main-bvxea6i-inhoolfrqniuu.eu-5.platformsh.site'
    
    # Get current date for date ranges
    start_date = datetime.now().strftime('%Y-%m-%d')
    end_date = (datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d')
    
    print(f'Creating scraping run with correct format...')
    
    # Correct format based on the error message
    correct_data = {
        "name": "Emergency Test Scraping Run",
        "project": 1,  # Try project 1
        "platform_services": [1],  # Instagram posts service
        "configuration": {
            "start_date": start_date,
            "end_date": end_date,
            "num_of_posts": 10,
            "platforms": ["instagram"],
            "services": ["posts"]
        }
    }
    
    print(f'üìã Test data:')
    print(json.dumps(correct_data, indent=2))
    print()
    
    try:
        response = requests.post(
            f'{base_url}/api/workflow/scraping-runs/',
            json=correct_data,
            headers={'Content-Type': 'application/json'},
            timeout=30
        )
        
        print(f'Status: {response.status_code}')
        print(f'Response: {response.text}')
        
        if response.status_code == 201:
            data = response.json()
            print(f'\nüéâ SUCCESS! Scraping run created!')
            print(f'   ID: {data.get("id")}')
            print(f'   Name: {data.get("name")}')
            print(f'   Status: {data.get("status")}')
            return data.get("id")
            
        elif response.status_code == 400:
            error_data = response.json()
            print(f'\n‚ùå Bad request - missing fields:')
            for field, errors in error_data.items():
                print(f'   {field}: {errors}')
                
        elif response.status_code == 502:
            print(f'\n‚ùå 502 - Server still restarting, try again in a moment')
            
        else:
            print(f'\n‚ö†Ô∏è  Unexpected status: {response.status_code}')
            
    except Exception as e:
        print(f'\n‚ùå Request error: {str(e)}')
    
    return None

def test_alternative_formats():
    print(f'\nüîç TESTING ALTERNATIVE FORMATS:')
    
    base_url = 'https://main-bvxea6i-inhoolfrqniuu.eu-5.platformsh.site'
    
    # Try simpler format
    simple_data = {
        "name": "Simple Test Run",
        "configuration": {
            "start_date": datetime.now().strftime('%Y-%m-%d'),
            "end_date": (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d'),
            "num_of_posts": 5
        }
    }
    
    print(f'1. Simple format:')
    print(json.dumps(simple_data, indent=2))
    
    try:
        response = requests.post(
            f'{base_url}/api/workflow/scraping-runs/',
            json=simple_data,
            timeout=20
        )
        print(f'   Status: {response.status_code}')
        if response.status_code != 201:
            print(f'   Error: {response.text[:200]}...')
    except Exception as e:
        print(f'   Error: {str(e)}')

def provide_frontend_fix():
    print(f'\nüîß FRONTEND FIX FOR YOUR WORKFLOW SERVICE:')
    print('=' * 50)
    
    frontend_fix = '''
// Fix your createScrapingRun method in workflowService.ts:

async createScrapingRun(data: CreateScrapingRunRequest): Promise<ScrapingRun> {
  try {
    // Add required date fields if missing
    const currentDate = new Date().toISOString().split('T')[0];
    const endDate = new Date(Date.now() + 30 * 24 * 60 * 60 * 1000).toISOString().split('T')[0];
    
    const requestData = {
      name: data.name || 'Scraping Run',
      project: data.project || 1,
      platform_services: data.platform_services || [1],
      configuration: {
        start_date: currentDate,
        end_date: endDate,
        num_of_posts: data.configuration?.num_of_posts || 10,
        platforms: data.configuration?.platforms || ['instagram'],
        services: data.configuration?.services || ['posts'],
        ...data.configuration
      }
    };

    const response = await apiFetch('/api/workflow/scraping-runs/', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestData),
    });

    if (response.ok) {
      return await response.json();
    } else if (response.status === 502) {
      throw new Error('Server is restarting, please wait a moment and try again');
    } else {
      const errorData = await response.json();
      throw new Error(`Failed to create scraping run: ${JSON.stringify(errorData)}`);
    }
  } catch (error) {
    console.error('Error creating scraping run:', error);
    throw error;
  }
}
'''
    
    print(frontend_fix)

if __name__ == '__main__':
    print('üö® FIXING SCRAPING-RUN 502/400 ERRORS')
    print('üö® TESTING CORRECT DATA FORMATS')
    print()
    
    # Test correct format
    run_id = test_correct_scraping_run_format()
    
    # Test alternatives if needed
    if not run_id:
        test_alternative_formats()
    
    # Provide frontend fix
    provide_frontend_fix()
    
    print(f'\nüìä SUMMARY:')
    print(f'‚úÖ Upsun deployment: Stable and working')
    print(f'‚úÖ Workflow endpoints: All responding 200')
    print(f'‚úÖ BrightData scraper: Still working perfectly')
    print(f'üîß Issue: Scraping-run needs correct date format')
    print(f'üíª Solution: Update frontend with proper data structure')
    
    if run_id:
        print(f'\nüéâ SUCCESS! Created scraping run ID: {run_id}')
        print(f'Your workflow system is now working!')