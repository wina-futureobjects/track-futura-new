#!/usr/bin/env python3
"""
BrightData Command Line Trigger Tool
Usage: python brightdata_cli.py [instagram|facebook|both]
"""
import sys
import requests
import json
import argparse
from datetime import datetime

class BrightDataCLI:
    def __init__(self):
        self.api_url = "https://main-bvxea6i-inhoolfrqniuu.eu-5.platformsh.site/api/brightdata/trigger-scraper/"
        
    def trigger_scraper(self, platform, urls=None):
        """Trigger a scraper for the specified platform"""
        if urls is None:
            urls = self.get_default_urls(platform)
            
        print(f"ðŸš€ Triggering {platform.title()} scraper...")
        print(f"ðŸ“‹ URLs: {', '.join(urls)}")
        print(f"â° Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("-" * 50)
        
        try:
            response = requests.post(
                self.api_url,
                json={
                    "platform": platform,
                    "urls": urls
                },
                headers={"Content-Type": "application/json"},
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get('success'):
                    print(f"âœ… SUCCESS! {platform.title()} scraper started!")
                    print(f"ðŸ“Š Job ID: {data.get('batch_job_id')}")
                    print(f"ðŸ“Š Dataset: {data.get('dataset_id')}")
                    print(f"ðŸ”— URLs Count: {data.get('urls_count')}")
                    print(f"ðŸ“ Message: {data.get('message')}")
                    print("ðŸ‘‰ Check your BrightData dashboard for progress!")
                    return True
                else:
                    print(f"âŒ ERROR: {data.get('error', 'Unknown error')}")
                    return False
            else:
                print(f"âŒ HTTP ERROR: {response.status_code}")
                print(f"Response: {response.text[:200]}")
                return False
                
        except requests.exceptions.Timeout:
            print("âŒ TIMEOUT: Request took too long")
            return False
        except requests.exceptions.ConnectionError:
            print("âŒ CONNECTION ERROR: Could not connect to server")
            return False
        except Exception as e:
            print(f"âŒ UNEXPECTED ERROR: {str(e)}")
            return False
    
    def get_default_urls(self, platform):
        """Get default URLs for each platform"""
        defaults = {
            'instagram': [
                'https://www.instagram.com/nike/',
                'https://www.instagram.com/adidas/',
                'https://www.instagram.com/cocacola/'
            ],
            'facebook': [
                'https://www.facebook.com/nike',
                'https://www.facebook.com/adidas',
                'https://www.facebook.com/cocacola'
            ]
        }
        return defaults.get(platform, [])
    
    def trigger_both(self):
        """Trigger both Instagram and Facebook scrapers"""
        print("ðŸŽ¯ TRIGGERING BOTH INSTAGRAM AND FACEBOOK SCRAPERS")
        print("=" * 60)
        
        results = {}
        
        # Trigger Instagram
        print("\nðŸ“¸ INSTAGRAM SCRAPER:")
        results['instagram'] = self.trigger_scraper('instagram')
        
        # Trigger Facebook  
        print("\nðŸ“˜ FACEBOOK SCRAPER:")
        results['facebook'] = self.trigger_scraper('facebook')
        
        # Summary
        print("\n" + "=" * 60)
        print("ðŸ“Š SUMMARY:")
        
        success_count = sum(results.values())
        if success_count == 2:
            print("ðŸŽ‰ Both scrapers started successfully!")
        elif success_count == 1:
            print("âš ï¸  One scraper started, one failed")
        else:
            print("âŒ Both scrapers failed")
            
        print(f"âœ… Instagram: {'Success' if results['instagram'] else 'Failed'}")
        print(f"âœ… Facebook: {'Success' if results['facebook'] else 'Failed'}")
        
        return success_count > 0

def main():
    parser = argparse.ArgumentParser(
        description="ðŸš€ BrightData Scraper Trigger CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python brightdata_cli.py instagram           # Trigger Instagram scraper
  python brightdata_cli.py facebook            # Trigger Facebook scraper  
  python brightdata_cli.py both                # Trigger both scrapers
  python brightdata_cli.py instagram --urls "https://www.instagram.com/custom/"
        """
    )
    
    parser.add_argument(
        'platform',
        choices=['instagram', 'facebook', 'both'],
        help='Platform to scrape (instagram, facebook, or both)'
    )
    
    parser.add_argument(
        '--urls',
        nargs='+',
        help='Custom URLs to scrape (space-separated)'
    )
    
    args = parser.parse_args()
    
    cli = BrightDataCLI()
    
    print("ðŸš€ BRIGHTDATA SCRAPER TRIGGER CLI")
    print("=" * 40)
    
    if args.platform == 'both':
        success = cli.trigger_both()
    else:
        success = cli.trigger_scraper(args.platform, args.urls)
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()