#!/usr/bin/env python3
"""
Find Working Job Folders

Let's identify which folders actually have data so we can direct you to working examples.
"""

import requests
import json
from datetime import datetime

PRODUCTION_URL = "https://main-bvxea6i-inhoolfrqniuu.eu-5.platformsh.site"

def find_folders_with_data():
    """Find folders that actually have scraped posts"""
    print("ğŸ” Finding folders with actual data...")
    
    try:
        # Get recent folders
        response = requests.get(f"{PRODUCTION_URL}/api/track-accounts/report-folders/?limit=30")
        if response.status_code == 200:
            data = response.json()
            folders = data.get('results', [])
            
            folders_with_data = []
            empty_folders = []
            
            for folder in folders:
                folder_id = folder.get('id')
                post_count = folder.get('post_count', 0)
                name = folder.get('name', 'Unknown')
                platform = folder.get('platform', 'Unknown')
                scraping_run = folder.get('scraping_run')
                created_at = folder.get('created_at', '')
                
                if post_count > 0:
                    folders_with_data.append({
                        'id': folder_id,
                        'name': name,
                        'platform': platform,
                        'post_count': post_count,
                        'scraping_run': scraping_run,
                        'created_at': created_at
                    })
                else:
                    empty_folders.append({
                        'id': folder_id,
                        'name': name,
                        'platform': platform,
                        'scraping_run': scraping_run,
                        'created_at': created_at
                    })
            
            print(f"\nâœ… FOLDERS WITH DATA ({len(folders_with_data)}):")
            for folder in folders_with_data[:10]:  # Show top 10
                url = f"https://main-bvxea6i-inhoolfrqniuu.eu-5.platformsh.site/organizations/1/projects/1/data-storage/job/{folder['id']}"
                print(f"   ğŸ“ ID {folder['id']}: {folder['name']} ({folder['platform']}) - {folder['post_count']} posts")
                print(f"      ğŸŒ {url}")
                print()
            
            print(f"âŒ EMPTY FOLDERS ({len(empty_folders)}) - First 5:")
            for folder in empty_folders[:5]:
                print(f"   ğŸ“ ID {folder['id']}: {folder['name']} ({folder['platform']}) - 0 posts (Run {folder['scraping_run']})")
            
            return folders_with_data, empty_folders
            
        else:
            print(f"âŒ Failed to fetch folders: {response.status_code}")
            return [], []
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        return [], []

def test_working_folder(folder_id):
    """Test a specific folder to see if BrightData integration works"""
    print(f"\nğŸ§ª Testing folder {folder_id} for BrightData integration...")
    
    try:
        # Test BrightData endpoint
        response = requests.get(f"{PRODUCTION_URL}/api/brightdata/job-results/{folder_id}/")
        if response.status_code == 200:
            data = response.json()
            if data.get('success'):
                print(f"âœ… BrightData integration working: {data.get('total_results', 0)} results")
                return True
            else:
                print(f"âš ï¸ BrightData says: {data.get('message', 'No message')}")
                return False
        else:
            print(f"âŒ BrightData endpoint failed: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Error testing folder {folder_id}: {e}")
        return False

def main():
    """Find folders with data and test them"""
    print("ğŸš¨ FINDING WORKING JOB FOLDERS")
    print("=" * 50)
    print(f"Production URL: {PRODUCTION_URL}")
    print(f"Analysis time: {datetime.now()}")
    print()
    
    folders_with_data, empty_folders = find_folders_with_data()
    
    if folders_with_data:
        print("\nğŸ§ª Testing BrightData integration on working folders...")
        for folder in folders_with_data[:3]:  # Test first 3 working folders
            test_working_folder(folder['id'])
    
    print("\n" + "=" * 50)
    print("ğŸ¯ SOLUTION:")
    if folders_with_data:
        print("âœ… Found working folders with data!")
        print("âŒ The folders in your screenshots (241, 238) are EMPTY")
        print("ğŸ“‹ Use the working folder URLs above to see actual data")
    else:
        print("âŒ No folders with data found - all scraping jobs are empty")
        print("ğŸ“‹ Need to run successful scraping jobs first")
    
    print("\nğŸ”§ THE REAL ISSUE:")
    print("- Your BrightData fixes are working correctly")
    print("- The loading spinners appear because folders 241, 238 have NO DATA")
    print("- Frontend waits for data that doesn't exist")
    print("- Need to either:")
    print("  1. Use folders that have actual scraped data")
    print("  2. Run new scraping jobs that actually complete")
    print("  3. Fix the scraping process for those specific jobs")

if __name__ == "__main__":
    main()