#!/usr/bin/env python3
"""
Fix pending scraping jobs in the Input Collection dashboard
"""

from brightdata_integration.models import BrightDataBatchJob, BrightDataScraperRequest
from django.utils import timezone

print("ğŸ”§ FIXING PENDING SCRAPING JOBS")
print("=" * 50)

# Check current batch jobs
batch_jobs = BrightDataBatchJob.objects.all().order_by('-created_at')
print(f"ğŸ“Š Total batch jobs: {batch_jobs.count()}")

pending_jobs = batch_jobs.filter(status='pending')
print(f"â³ Pending jobs: {pending_jobs.count()}")

# Update pending jobs to completed where we have scraped data
for job in pending_jobs[:10]:  # Process first 10
    print(f"\nğŸ” Processing Job {job.id}:")
    print(f"   Name: {job.name}")
    print(f"   Status: {job.status}")
    print(f"   Created: {job.created_at}")
    
    # Check if we have related scraper requests that completed
    related_requests = BrightDataScraperRequest.objects.filter(
        folder_id__in=job.source_folder_ids if job.source_folder_ids else []
    )
    
    completed_requests = related_requests.filter(status='completed')
    failed_requests = related_requests.filter(status='failed')
    
    print(f"   Related requests: {related_requests.count()}")
    print(f"   Completed requests: {completed_requests.count()}")
    print(f"   Failed requests: {failed_requests.count()}")
    
    # Update job status based on requests
    if completed_requests.exists():
        job.status = 'completed'
        job.progress = 100
        job.completed_at = timezone.now()
        if not job.started_at:
            job.started_at = job.created_at
        job.save()
        print(f"   âœ… Updated to completed")
    elif failed_requests.count() == related_requests.count() and related_requests.exists():
        job.status = 'failed'
        job.completed_at = timezone.now()
        if not job.started_at:
            job.started_at = job.created_at
        job.save()
        print(f"   âŒ Updated to failed")
    else:
        # If job is older than 1 hour and still pending, mark as failed
        if timezone.now() - job.created_at > timezone.timedelta(hours=1):
            job.status = 'failed'
            job.error_log = 'Job timed out - no response from BrightData'
            job.completed_at = timezone.now()
            if not job.started_at:
                job.started_at = job.created_at
            job.save()
            print(f"   â° Marked as failed (timeout)")
        else:
            print(f"   â³ Keeping as pending")

# Summary
print(f"\nğŸ“ˆ FINAL STATUS:")
batch_jobs_updated = BrightDataBatchJob.objects.all()
for status in ['pending', 'processing', 'completed', 'failed']:
    count = batch_jobs_updated.filter(status=status).count()
    print(f"   {status.title()}: {count}")

print(f"\nğŸ‰ SCRAPING JOBS STATUS UPDATE COMPLETE!")
print("âœ… Pending jobs have been resolved")
print("âœ… Input Collection dashboard should now show correct statuses")